{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import misc\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import argparse\n",
    "import torchvision\n",
    "## Load the model \n",
    "#model_conv = torchvision.models.inception_v3(pretrained='imagenet',aux_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t=np.array([[1,1,1],[2,2,2],[3,3,3]])\n",
    "t=Variable(torch.from_numpy(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, param in model_conv.named_parameters():\n",
    "    param.requires_grad = False\n",
    "ct = []\n",
    "for name, child in model_conv.named_children():\n",
    "    if \"Mixed_7c\" in ct:\n",
    "        for params in child.parameters():\n",
    "            params.requires_grad = True\n",
    "    ct.append(name)\n",
    "\n",
    "model_conv.fc = nn.Linear(2048, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_conv.AuxLogits.fc=nn.Linear(19200, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for params in model_conv.AuxLogits.fc.parameters():\n",
    "    params.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=19200, out_features=30, bias=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_conv.AuxLogits.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Lets freeze the first few layers. This is done in two stages \n",
    "# Stage-1 Freezing all the layers \n",
    "if freeze_layers:\n",
    "    for i, param in model_conv.named_parameters():\n",
    "        param.requires_grad = False\n",
    "# Since imagenet as 1000 classes , We need to change our last layer according to the number of classes we have,\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, n_class)\n",
    "\n",
    "# Stage-2 , Freeze all the layers till \"Conv2d_4a_3*3\"\n",
    "ct = []\n",
    "for name, child in model_conv.named_children():\n",
    "    if \"Conv2d_4a_3x3\" in ct:\n",
    "        for params in child.parameters():\n",
    "            params.requires_grad = True\n",
    "    ct.append(name)\n",
    "    \n",
    "# To view which layers are freeze and which layers are not freezed:\n",
    "for name, child in model_conv.named_childeren():\n",
    "    for name_2, params in child.named_parameters():\n",
    "        print(name_2, params.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5,stride=3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5,stride=3)\n",
    "        self.fc1   = nn.Linear(2704, 120)\n",
    "#         16*5*5\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.softmax(self.fc3(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class sensenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sensenet, self).__init__()\n",
    "        self.glob_conv_1x1=nn.Conv2d(3,6,1)\n",
    "        \n",
    "        self.glob_conv_3x3=nn.Conv2d(6,256,3)\n",
    "        self.avgpool_3=nn.AvgPool2d(254)\n",
    "        \n",
    "        self.glob_conv_5x5=nn.Conv2d(6,256,5)\n",
    "        self.avgpool_5=nn.AvgPool2d(300)\n",
    "        \n",
    "        self.glob_conv_7x7=nn.Conv2d(6,256,7)\n",
    "        self.avgpool_7=nn.AvgPool2d(300)\n",
    "        \n",
    "        \n",
    "        self.detail_conv_3x3_s2_a=BasicConv2d(3, 6, kernel_size=3, stride=2)\n",
    "        self.detail_conv_3x3_s2_b=BasicConv2d(6, 36, kernel_size=3, stride=2)\n",
    "        self.detail_conv_3x3_c=BasicConv2d(36, 216, kernel_size=3)\n",
    "        self.detail_conv_3x3_d=BasicConv2d(216, 512, kernel_size=3)\n",
    "        \n",
    "        self.glob_fc=nn.Linear(100,30)\n",
    "#         self.conv1 = nn.Conv2d(3, 6, 5,stride=3)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5,stride=3)\n",
    "#         self.fc1   = nn.Linear(2704, 120)\n",
    "# #         16*5*5\n",
    "#         self.fc2   = nn.Linear(120, 84)\n",
    "#         self.fc3   = nn.Linear(84, 30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        g_out=self.glob_conv_1x1(x)\n",
    "        \n",
    "        g_out_3=self.glob_conv_3x3(g_out)\n",
    "        avg_3 = self.avgpool_3(g_out_3)\n",
    "        \n",
    "        g_out_5=self.glob_conv_5x5(g_out)\n",
    "        avg_5 = self.avgpool_5(g_out_5)\n",
    "        \n",
    "        g_out_7=self.glob_conv_7x7(g_out)\n",
    "        avg_7 = self.avgpool_7(g_out_7)\n",
    "        \n",
    "        g_avg=torch.cat((avg_3,avg_5), 0)\n",
    "        g_avg=torch.cat((g_avg,avg_7), 0)\n",
    "        \n",
    "        d_out=self.detail_conv_3x3_s2_a(x)\n",
    "        d_out=self.detail_conv_3x3_s2_b(dout)\n",
    "        \n",
    "        d_out=self.detail_conv_3x3_c(dout)\n",
    "        d_out = F.max_pool2d(d_out, kernel_size=3)\n",
    "        \n",
    "        d_out=self.detail_conv_3x3_d(dout)\n",
    "        d_out = F.max_pool2d(d_out, kernel_size=3)\n",
    "        \n",
    "        d_out = d_out.view(d_out.size(0), -1)\n",
    "        \n",
    "        final_vec=torch.cat((g_avg,d_out), 0)\n",
    "        \n",
    "        out=self.glob_fc=nn.Linear(final_vec)\n",
    "        return out\n",
    "    \n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 120\n",
    "num_classes = 30\n",
    "img_width, img_height = 512, 512  # input image dimensions\n",
    "\n",
    "PATH = os.path.abspath('/home/yicheng/DS/scraper/styles_cropped')\n",
    "class_lst = listdir(PATH) # all string filenames in a list\n",
    "path_dic = {}\n",
    "for Class in class_lst:\n",
    "    SOURCE_IMAGES = os.path.join(PATH, Class)\n",
    "    images = [SOURCE_IMAGES+'/'+f for f in listdir(SOURCE_IMAGES) ]\n",
    "    path_dic[Class] = images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_class_to_index={}\n",
    "for i in range(len(class_lst)):\n",
    "    map_class_to_index[class_lst[i]]=i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_loader(batch_size,class_lst,select_index):\n",
    "    target_values=[]\n",
    "    img_mats=[]\n",
    "    counter=1\n",
    "    for n in select_index:\n",
    "        for style in class_lst:\n",
    "            mat=misc.imread(path_dic[style][n])\n",
    "            mat=np.array(mat)\n",
    "            if len(mat.shape)<3:\n",
    "                mat=np.expand_dims(mat, axis=2)\n",
    "                mat=np.repeat(mat,3,axis=2)\n",
    "            elif mat.shape[2]==1:\n",
    "                mat=np.repeat(mat,3,axis=2)\n",
    "            elif mat.shape[2]>3:\n",
    "                mat=mat[:,:,:3]\n",
    "            #mat=mat[:256,:256,:]\n",
    "            mat=np.swapaxes(mat,0,2)\n",
    "            mat=np.expand_dims(mat, axis=0)\n",
    "            img_mats.append(mat)\n",
    "            target_values.append(map_class_to_index[style])\n",
    "        \n",
    "        if counter % batch_size==0:\n",
    "            #yield (np.asarray(img_mats),np.asarray(target_values))\n",
    "            yield (np.concatenate(img_mats,axis=0),np.array(target_values))\n",
    "            target_values=[]\n",
    "            img_mats=[]\n",
    "        counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader=data_loader(1,class_lst,np.arange(1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 3, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "for i in train_loader:\n",
    "    print(i[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class sensenet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sensenet, self).__init__()\n",
    "        self.glob_conv_1x1=nn.Conv2d(3,3,3,stride=3)\n",
    "        \n",
    "        self.glob_conv_3x3=nn.Conv2d(3,128,3)\n",
    "\n",
    "        \n",
    "        self.glob_conv_5x5=nn.Conv2d(3,128,5)\n",
    "\n",
    "\n",
    "        self.glob_conv_7x7=nn.Conv2d(3,128,7)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.detail_conv_3x3_s2_a=BasicConv2d(3, 6, kernel_size=4, stride=3)\n",
    "        self.detail_conv_3x3_s2_b=BasicConv2d(6, 36, kernel_size=3, stride=2)\n",
    "        self.detail_conv_3x3_c=BasicConv2d(36, 128, kernel_size=3)\n",
    "        self.detail_conv_3x3_d=BasicConv2d(128, 216, kernel_size=3)\n",
    "        self.glob_fc_1=nn.Linear(14208,30)\n",
    "#         self.glob_fc_2=nn.Linear(1000,300)\n",
    "#         self.glob_fc_3=nn.Linear(300,30)\n",
    "#         self.conv1 = nn.Conv2d(3, 6, 5,stride=3)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5,stride=3)\n",
    "#         self.fc1   = nn.Linear(2704, 120)\n",
    "# #         16*5*5\n",
    "#         self.fc2   = nn.Linear(120, 84)\n",
    "#         self.fc3   = nn.Linear(84, 30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        g_out=self.glob_conv_1x1(x)\n",
    "        g_out_3=self.glob_conv_3x3(g_out)\n",
    "        g_avg_3=g_out_3.mean(2,keepdim=True)\n",
    "        g_avg_3=g_avg_3.mean(3,keepdim=True)\n",
    "        g_avg_3=g_avg_3.squeeze(2)\n",
    "        g_avg_3=g_avg_3.squeeze(2)\n",
    "\n",
    "\n",
    "        g_out_5=self.glob_conv_5x5(g_out)\n",
    "        g_avg_5=g_out_5.mean(2,keepdim=True)\n",
    "        g_avg_5=g_avg_5.mean(3,keepdim=True)\n",
    "        g_avg_5=g_avg_5.squeeze(2)\n",
    "        g_avg_5=g_avg_5.squeeze(2)\n",
    "\n",
    "        g_out_7=self.glob_conv_7x7(g_out)\n",
    "        g_avg_7=g_out_7.mean(2,keepdim=True)\n",
    "        g_avg_7=g_avg_7.mean(3,keepdim=True)\n",
    "        g_avg_7=g_avg_7.squeeze(2)\n",
    "        g_avg_7=g_avg_7.squeeze(2)\n",
    "\n",
    "        g_avg=torch.cat((g_avg_3,g_avg_5), 1)\n",
    "        g_avg=torch.cat((g_avg,g_avg_7), 1)\n",
    "        \n",
    "#        out=g_avg\n",
    "        \n",
    "        d_out=self.detail_conv_3x3_s2_a(x)\n",
    "        d_out=self.detail_conv_3x3_s2_b(d_out)\n",
    "        \n",
    "        d_out=self.detail_conv_3x3_c(d_out)\n",
    "        d_out = F.max_pool2d(d_out, kernel_size=3)\n",
    "        \n",
    "        d_out=self.detail_conv_3x3_d(d_out)\n",
    "        d_out = F.max_pool2d(d_out, kernel_size=3)\n",
    "        #print(d_out.size())\n",
    "        d_out = d_out.view(d_out.size(0), -1)\n",
    "        #print(d_out.size())\n",
    "        final_vec=torch.cat((g_avg,d_out), 1)\n",
    "        \n",
    "        #print(final_vec.size())\n",
    "        out=self.glob_fc_1(final_vec)\n",
    "#         out=F.Sigmoid(out)\n",
    "#         out=self.glob_fc_2(out)\n",
    "        out=F.sigmoid(out)\n",
    "#         out=self.glob_fc_3(out)\n",
    "        return out\n",
    "    \n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SNet, self).__init__()\n",
    "        self.glob_conv_1x1=nn.Conv2d(3,3,2,stride=2)\n",
    "        \n",
    "        self.glob_conv_3x3=nn.Conv2d(3,64,3)\n",
    "\n",
    "        \n",
    "        self.glob_conv_5x5=nn.Conv2d(3,64,5)\n",
    "\n",
    "\n",
    "        #self.glob_conv_7x7=nn.Conv2d(3,64,7)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.detail_conv_3x3_s2_a=BasicConv2d(3, 32, kernel_size=3, stride=2)\n",
    "        self.detail_conv_3x3_s2_b=BasicConv2d(32, 64, kernel_size=3, stride=2)\n",
    "        self.inception_1=Inception(64,256)\n",
    "        self.inception_2=Inception(64,256)\n",
    "        self.inception_3=Inception(64,256)\n",
    "        self.inception_4=Inception_B(64,256)\n",
    "#         self.detail_conv_3x3_c=BasicConv2d(64, 128, kernel_size=3)\n",
    "#         self.detail_conv_3x3_d=BasicConv2d(128, 216, kernel_size=3)\n",
    "        self.glob_fc_1=nn.Linear(3264,30)\n",
    "#         self.glob_fc_2=nn.Linear(1000,300)\n",
    "#         self.glob_fc_3=nn.Linear(300,30)\n",
    "#         self.conv1 = nn.Conv2d(3, 6, 5,stride=3)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, 5,stride=3)\n",
    "#         self.fc1   = nn.Linear(2704, 120)\n",
    "# #         16*5*5\n",
    "#         self.fc2   = nn.Linear(120, 84)\n",
    "#         self.fc3   = nn.Linear(84, 30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        g_out=self.glob_conv_1x1(x)\n",
    "        g_out_3=self.glob_conv_3x3(g_out)\n",
    "        g_avg_3=g_out_3.mean(2,keepdim=True)\n",
    "        g_avg_3=g_avg_3.mean(3,keepdim=True)\n",
    "        g_avg_3=g_avg_3.squeeze(2)\n",
    "        g_avg_3=g_avg_3.squeeze(2)\n",
    "\n",
    "\n",
    "        g_out_5=self.glob_conv_5x5(g_out)\n",
    "        g_avg_5=g_out_5.mean(2,keepdim=True)\n",
    "        g_avg_5=g_avg_5.mean(3,keepdim=True)\n",
    "        g_avg_5=g_avg_5.squeeze(2)\n",
    "        g_avg_5=g_avg_5.squeeze(2)\n",
    "\n",
    "#         g_out_7=self.glob_conv_7x7(g_out)\n",
    "#         g_avg_7=g_out_7.mean(2,keepdim=True)\n",
    "#         g_avg_7=g_avg_7.mean(3,keepdim=True)\n",
    "#         g_avg_7=g_avg_7.squeeze(2)\n",
    "#         g_avg_7=g_avg_7.squeeze(2)\n",
    "\n",
    "        g_avg=torch.cat((g_avg_3,g_avg_5), 1)\n",
    "#         g_avg=torch.cat((g_avg,g_avg_7), 1)\n",
    "        \n",
    "#        out=g_avg\n",
    "        \n",
    "        d_out=self.detail_conv_3x3_s2_a(x)\n",
    "        d_out=self.detail_conv_3x3_s2_b(d_out)\n",
    "        d_out = F.max_pool2d(d_out, kernel_size=2)\n",
    "        \n",
    "        d_out=self.inception_1(d_out)\n",
    "        d_out=self.inception_2(d_out)\n",
    "        d_out=self.inception_3(d_out)\n",
    "        \n",
    "        d_out = F.max_pool2d(d_out, kernel_size=2)\n",
    "        \n",
    "        d_out=self.inception_4(d_out)\n",
    "        d_out = F.max_pool2d(d_out, kernel_size=2)\n",
    "        d_out=self.inception_4(d_out)\n",
    "        \n",
    "        d_out = F.max_pool2d(d_out, kernel_size=2)\n",
    "        \n",
    "#         d_out=self.detail_conv_3x3_c(d_out)\n",
    "#         d_out = F.max_pool2d(d_out, kernel_size=3)\n",
    "        \n",
    "#         d_out=self.detail_conv_3x3_d(d_out)\n",
    "#         d_out = F.max_pool2d(d_out, kernel_size=3)\n",
    "#         #print(d_out.size())\n",
    "        d_out = d_out.view(d_out.size(0), -1)\n",
    "        #print(d_out.size())\n",
    "        final_vec=torch.cat((g_avg,d_out), 1)\n",
    "        \n",
    "        #print(final_vec.size())\n",
    "        out=self.glob_fc_1(final_vec)\n",
    "#         out=F.Sigmoid(out)\n",
    "#         out=self.glob_fc_2(out)\n",
    "        out=F.sigmoid(out)\n",
    "#         out=self.glob_fc_3(out)\n",
    "        return out\n",
    "    \n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return F.relu(x, inplace=True)\n",
    "    \n",
    "class Inception(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channels,out_channels=256,**kwargs):\n",
    "        super(Inception, self).__init__()\n",
    "        self.conv1x1_s=BasicConv2d(in_channels,64,kernel_size=1)\n",
    "        self.conv3x3=BasicConv2d(64,out_channels,kernel_size=3,padding=1)\n",
    "        self.conv5x5=BasicConv2d(64,out_channels,kernel_size=5,padding=2)\n",
    "        self.conv1x1_e=BasicConv2d(576,64,kernel_size=1)\n",
    "    def forward(self,x):\n",
    "        m=self.conv1x1_s(x)\n",
    "        b1=self.conv3x3(m)\n",
    "        b2=self.conv5x5(m)\n",
    "        b3=F.avg_pool2d(x,kernel_size=3,stride=1,padding=1)\n",
    "        \n",
    "        out=[b1,b2,b3]\n",
    "        out=torch.cat(out,dim=1)\n",
    "        out=self.conv1x1_e(out)\n",
    "        return out\n",
    "    \n",
    "class Inception_B(nn.Module):\n",
    "    \n",
    "    def __init__(self,in_channels,out_channels=256,**kwargs):\n",
    "        super(Inception_B, self).__init__()\n",
    "        self.conv1x1_s=BasicConv2d(in_channels,64,kernel_size=1)\n",
    "        self.conv3x3=BasicConv2d(64,out_channels,kernel_size=3,padding=1)\n",
    "        self.conv1x5=BasicConv2d(64,out_channels,kernel_size=[1,5],padding=[0,2])\n",
    "        self.conv5x1=BasicConv2d(out_channels,out_channels,kernel_size=[5,1],padding=[2,0])\n",
    "        self.conv1x1_e=BasicConv2d(576,64,kernel_size=1)\n",
    "    def forward(self,x):\n",
    "        m=self.conv1x1_s(x)\n",
    "        \n",
    "        b1=self.conv3x3(m)\n",
    "        \n",
    "        b2=self.conv1x5(m)\n",
    "        b2=self.conv5x1(b2)\n",
    "        \n",
    "        b3=F.avg_pool2d(x,kernel_size=3,stride=1,padding=1)\n",
    "        \n",
    "        out=[b1,b2,b3]\n",
    "        out=torch.cat(out,dim=1)\n",
    "        out=self.conv1x1_e(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2550149"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(SNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "751918"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(sensenet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1524590031827/work/aten/src/THC/generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4e39308c1337>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_lst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m750\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_lst\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m751\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-4e39308c1337>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m#print(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mCEloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-63f5e7dbd9b7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0md_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0md_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minception_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0md_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minception_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0md_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minception_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-63f5e7dbd9b7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1x1_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-63f5e7dbd9b7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1524590031827/work/aten/src/THC/generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "cuda=True\n",
    "lr=0.001\n",
    "momentum=0.5\n",
    "log_interval=10\n",
    "epochs=70\n",
    "batch_size=1\n",
    "# model = LeNet()\n",
    "#model=model_conv\n",
    "\n",
    "model=SNet()\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(list(filter(lambda p: p.requires_grad, model.parameters())), lr=lr, momentum=momentum)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (input_data, input_target) in enumerate(train_loader):\n",
    "        print(batch_idx)\n",
    "        data=torch.FloatTensor(input_data)\n",
    "\n",
    "        target=torch.LongTensor(input_target)\n",
    "\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #print(output)\n",
    "        CEloss = nn.CrossEntropyLoss()\n",
    "        loss = CEloss(output, target)\n",
    "        #print(output.data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), 750*30,\n",
    "                100. * batch_idx / (750/batch_size), loss.data[0]))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for input_data, input_target in test_loader:\n",
    "        \n",
    "        data=torch.FloatTensor(input_data)\n",
    "\n",
    "        target=torch.LongTensor(input_target)\n",
    "\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "        test_loss += loss(output, target).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= 250*30\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, 250*30,\n",
    "        100. * correct / (250*30)))\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loader=data_loader(batch_size,class_lst,np.arange(750))\n",
    "    train(epoch)\n",
    "    test_loader=data_loader(batch_size,class_lst,np.arange(751,1000))\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d21732fc0da8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "args.cuda=False\n",
    "args.lr=0.001\n",
    "args.momentum=0.5\n",
    "\n",
    "\n",
    "model = LeNet()\n",
    "if args.cuda:\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data=torch.from_numpy(data)\n",
    "        target=torch.from_numpy(target)\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data=torch.from_numpy(data)\n",
    "        target=torch.from_numpy(target)\n",
    "        if args.cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)\n",
    "    test()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
